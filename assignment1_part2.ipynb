{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "750c59ea35055ffcae44b56af8be7cfd",
     "grade": false,
     "grade_id": "cell-1262282752ee17cb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "version = \"v2.0.220705.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either of the following is no longer\n",
    "# necessary for matplotlib in notebooks.\n",
    "# The import statement has you covered!\n",
    "\n",
    "# %matplotlib notebook\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress all warnings only when absolutely necessary\n",
    "# Warnings are in place for a reason!\n",
    "import warnings\n",
    "\n",
    "# warnings.filterwarnings('ignore')\n",
    "# warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b366bbef6251ec4b5104563adca51a00",
     "grade": false,
     "grade_id": "cell-cf5099926e9f16fa",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Assignment 1 Part 2: Introduction to Supervised Machine Learning\n",
    "In this assignment you will be using the [Breast Cancer Wisconsin (Diagnostic)](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)) dataset to create a classifier that can help diagnose patients. We chose this data not only because it provides a good basis for a kNN classification problem, but also because it illustrates one of the built-in datasets that comes with `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4dff058347a0973a65761d7204e3da43",
     "grade": false,
     "grade_id": "cell-7696bde2345190bb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Import some necessary libararies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.set_printoptions(precision=3)\n",
    "\n",
    "## Additional imports can be inlcuded here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1c81e667af370b53c36e5251b03a0c8",
     "grade": false,
     "grade_id": "cell-98fe1e589fe08996",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset from scikit-learn.\n",
    "\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see a description of the dataset,\n",
    "# uncomment the following print statement\n",
    "\n",
    "# print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8585aa96617786d422eed7d3a54d7d41",
     "grade": false,
     "grade_id": "cell-fa8993b2db96f976",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The object returned by `load_breast_cancer()` is a scikit-learn `bunch` object, which is similar to a Python dictionary.  \n",
    "To view the `bunch` attributes, use the `.keys()` method of the cancer object. Feel free to explore this object yourself.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7837834a64c60a4a751075f41dcea3bc",
     "grade": false,
     "grade_id": "cell-5192a5893e9a8115",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 0. Warm-up (5 pts)\n",
    "\n",
    "Understanding how many features you're dealing with and what each feature represents is an essential first step in machine learning.  So, how many features are there in this dataset? Complete the function below to return the answer as an integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8cbceb11568c4eb5bfe6d859e85f4490",
     "grade": false,
     "grade_id": "cell-0562c45651419b03",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_zero():\n",
    "    \"\"\"\n",
    "    This function returns the number of features of the breast cancer dataset as an integer.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    return cancer['feature_names'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use this cell to explore your solution\n",
    "# remember to comment the function call before submitting the notebook\n",
    "\n",
    "answer_zero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c94753e2d4714bd8a0aac53529f82a9a",
     "grade": true,
     "grade_id": "cell-919dd7f0bfcbfd9a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests Below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a9f11e9a1043924800a48d69e643a9a",
     "grade": false,
     "grade_id": "cell-d17102a8aade0d25",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 1. Data Transformation (10 pts)\n",
    "\n",
    "In a lot of cases, raw data may not come in a form that's amenable to further manipulation or interpretation. Therefore, we may need to transform the raw data so that it better fits our purposes. In this assignment, we will store the data in a more human-friendly tabular format as a `pd.DataFrame`.\n",
    "\n",
    "Complete the function below to return a `pd.DataFrame` of the shape `(569, 31)` with the following columns: \n",
    "```\n",
    "['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
    "'mean smoothness', 'mean compactness', 'mean concavity',\n",
    "'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
    "'radius error', 'texture error', 'perimeter error', 'area error',\n",
    "'smoothness error', 'compactness error', 'concavity error',\n",
    "'concave points error', 'symmetry error', 'fractal dimension error',\n",
    "'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
    "'worst smoothness', 'worst compactness', 'worst concavity',\n",
    "'worst concave points', 'worst symmetry', 'worst fractal dimension',\n",
    "'target']\n",
    "```\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "075ab0d8fcdfac59802c55d77910a932",
     "grade": false,
     "grade_id": "cell-7da0be2f62cc82c6",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_one():\n",
    "    cancer_df = None\n",
    "    cancer_df = pd.DataFrame(data = cancer['data'],columns = cancer['feature_names'])\n",
    "    cancer_df['target'] = cancer['target']\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    return cancer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use this cell to explore your solution\n",
    "# # remember to comment the function call before submitting the notebook\n",
    "\n",
    "# answer_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43fbe2a3f1fb390e17a8fe484e2ce381",
     "grade": true,
     "grade_id": "cell-50152fa70665c294",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_one()\n",
    "\n",
    "assert stu_ans.shape == (569, 31), \"Q1: The shape of your dataframe isn't correct. \"\n",
    "\n",
    "assert list(stu_ans.columns) == [\n",
    "    \"mean radius\",\n",
    "    \"mean texture\",\n",
    "    \"mean perimeter\",\n",
    "    \"mean area\",\n",
    "    \"mean smoothness\",\n",
    "    \"mean compactness\",\n",
    "    \"mean concavity\",\n",
    "    \"mean concave points\",\n",
    "    \"mean symmetry\",\n",
    "    \"mean fractal dimension\",\n",
    "    \"radius error\",\n",
    "    \"texture error\",\n",
    "    \"perimeter error\",\n",
    "    \"area error\",\n",
    "    \"smoothness error\",\n",
    "    \"compactness error\",\n",
    "    \"concavity error\",\n",
    "    \"concave points error\",\n",
    "    \"symmetry error\",\n",
    "    \"fractal dimension error\",\n",
    "    \"worst radius\",\n",
    "    \"worst texture\",\n",
    "    \"worst perimeter\",\n",
    "    \"worst area\",\n",
    "    \"worst smoothness\",\n",
    "    \"worst compactness\",\n",
    "    \"worst concavity\",\n",
    "    \"worst concave points\",\n",
    "    \"worst symmetry\",\n",
    "    \"worst fractal dimension\",\n",
    "    \"target\",\n",
    "], \"Q1: Please check the column names of your dataframe.\"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a78261568dfb9f1adeafa68b99ef8585",
     "grade": false,
     "grade_id": "cell-151d159eb6cc7465",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 2. Class Distribution (5 pts) \n",
    "\n",
    "It's often a good idea to get some descriptive statistics, such as mean and variance of certain features, on the data at hand to understand the big picture. \n",
    "\n",
    "In particular, it's always a good idea to ask: what is the class distribution? That is, how many instances belong to the *malignant* class (encoded as 0) and the *benign* class (encoded as 1), respectively? Complete the function below to return the class distribution as a `pd.Series` of length 2 whose index is  `['malignant', 'benign']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba5a7e6e053258df7c3520586446e725",
     "grade": false,
     "grade_id": "cell-fac24fc5a519ef06",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_two():\n",
    "    dist = None\n",
    "    df = answer_one()\n",
    "    dic = {1: 'benign',0:'malignant'}\n",
    "    df['target'] = df['target'].apply(lambda x : dic[x])\n",
    "    dist = df['target'].value_counts()\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to explore your solution\n",
    "# remember to comment the function call before submitting the notebook\n",
    "\n",
    "# answer_two()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "620d2ce47498341c76fd5e39c245a34a",
     "grade": true,
     "grade_id": "cell-1ebcc2fe5b95b5df",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_two()\n",
    "\n",
    "assert isinstance(stu_ans, pd.Series), \"Q2: Your result should be a pd.Series.\"\n",
    "\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "50408d3338c749f48f8827a5dc46afac",
     "grade": false,
     "grade_id": "cell-33882a911ba5c477",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 3. Data Preparation (5 pts)\n",
    "\n",
    "Training a classifier is a *supervised* machine learning problem, in which each instance $x_i$ has a corresponding class label $y_i$. All the instances $x_i$'s are collected into a matrix $X$ (with one instance per row of $X$), and all the corresponding labels are put into a column vector $y$. \n",
    "\n",
    "Now let's prepare the data for use with `scikit-learn`. Complete the function below to split our DataFrame into `X` (the data) and `y` (the labels), and to return them as a `tuple`, where\n",
    "* `X` is a `pd.DataFrame` of the shape `(569, 30)`\n",
    "* `y` is a `pd.Series` of the shape `(569,)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = answer_one()\n",
    "l = list(df.columns)\n",
    "l.remove('target')\n",
    "X = df[l]\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b860b5f7094b4259d70015f5f1b4ad7",
     "grade": false,
     "grade_id": "cell-61b34fdd39e99b03",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_three():\n",
    "    X, y = None, None\n",
    "    df = answer_one()\n",
    "    l = list(df.columns)\n",
    "    l.remove('target')\n",
    "    X = df[l]\n",
    "    y = df['target']\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to explore your solution\n",
    "# remember to comment the function call before submitting the notebook\n",
    "\n",
    "# answer_three()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "233b248f916f4429483a55565b3ea3f3",
     "grade": true,
     "grade_id": "cell-0bd5392f7412ea87",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_three()\n",
    "\n",
    "assert isinstance(stu_ans, tuple), \"Q3: You should return a tuple!\"\n",
    "assert isinstance(stu_ans[0], pd.DataFrame), \"Q3: X should be a pd.DataFrame. \"\n",
    "assert isinstance(stu_ans[1], pd.Series), \"Q3: y should be a pd.Series. \"\n",
    "assert stu_ans[0].shape == (569, 30), \"Q3: Please check the shape of X.\"\n",
    "assert stu_ans[1].shape == (569,), \"Q3: Please check the shape of y.\"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "059c086ea299afaea520c438cb634767",
     "grade": false,
     "grade_id": "cell-69dd1eef26cd5aac",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 4. Train-test Split (10 pts)\n",
    "\n",
    "For a typical machine learning problem, we'd need two separate datasets, one for training a model and the other for evaluating the trained model for its generalisability to unseen data. `scikit-learn` provides a very handy [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function for this purpose.  \n",
    "\n",
    "Now, complete the function below that uses the `train_test_split` function to split `X` and `y` into training and testing sets. Your function should return a `tuple` `(X_train, X_test, y_train, and y_test)` where\n",
    "\n",
    "\n",
    "* `X_train` is of the shape `(426, 30)`\n",
    "* `X_test` is of the shape `(143, 30)`\n",
    "* `y_train` is of the shape `(426,)`\n",
    "* `y_test` is of the shape `(143,)`\n",
    "\n",
    "**IMPORTANT: Set the random number generator state to the number 42 by specifying `random_state=42` to ensure a deterministic result that matches that of the autograder.**   Why the number 42?  Please see: https://www.theguardian.com/books/2011/feb/03/douglas-adams-42-hitchhiker\n",
    "\n",
    "(In later work, we'll actually use a slightly more sophisticated splitting scheme that uses training, validation, and test sets, but we'll cover this later as part of a technique called cross-validation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.25,random_state =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ea36fc73b83767d14cfb780cf0d93b5",
     "grade": false,
     "grade_id": "cell-8e5c85428bc3e008",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def answer_four():\n",
    "    X_train, X_test, y_train, y_test = (None,) * 4\n",
    "    X, y = answer_three()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use this cell to explore your solution\n",
    "# # remember to comment the function call before submitting the notebook\n",
    "\n",
    "# answer_four()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49a1560f285f57d78e10ec222e74a411",
     "grade": true,
     "grade_id": "cell-7c3f4473c01b46df",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_four()\n",
    "\n",
    "assert stu_ans[0].shape == (426, 30), \"Q4: Please check the shape of X_train.\"\n",
    "assert stu_ans[1].shape == (143, 30), \"Q4: Please check the shape of X_test.\"\n",
    "assert stu_ans[2].shape == (426,), \"Q4: Please check the shape of y_train.\"\n",
    "assert stu_ans[3].shape == (143,), \"Q4: Please check the shape of y_test.\"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4ac8dec823c48ef7fc516164b6531c99",
     "grade": false,
     "grade_id": "cell-eef73d2512084cc8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 5. kNN Classifier Construction (5 pts)\n",
    "\n",
    "Use `KNeighborsClassifier` from `scikit-learn` to fit a $k$-Nearest Neighbours ($k$NN) classifier with `X_train` and `y_train` where $k = 1$. Your function should return the trained classifier itself, which is a `sklearn.neighbors.KNeighborsClassifier` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4706fdb9f2109e58a51f31338855b197",
     "grade": false,
     "grade_id": "cell-4b71f9b9bd2e9139",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "def answer_five():\n",
    "    knn = None\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use this cell to explore your solution\n",
    "# # remember to comment the function call before submitting the notebook\n",
    "\n",
    "# answer_five()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59c58b3363e69e227d2fbc5e8b197d69",
     "grade": true,
     "grade_id": "cell-746df875c076339d",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_five()\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans, KNeighborsClassifier\n",
    "), \"Q5: Please build the required kNN classifier.\"\n",
    "\n",
    "assert (\n",
    "    len(stu_ans.classes_) == 2\n",
    "), \"Q5: Your kNN classifier was trained with an incorrect # classes. \"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f626c2c26008ad59fa441c7d2db3fc7",
     "grade": false,
     "grade_id": "cell-2ae5512e5f925fd8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 6. kNN Prediction on Mean Vector (10 pts)\n",
    "\n",
    "It's often useful and interesting to know what class a \"typical\" or \"average\" data point belongs to. Use your kNN classifier from the last question to predict the class label for the *mean vector* of the training data. Your function should return the predicted class label as a singleton numpy array --- either `array([ 0.])` or `array([ 1.])`. \n",
    "\n",
    "If you encounter errors complaining that the shape of your data isn't correct, carefully check the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.predict) of the `predict` function. Another useful hint is to consider what kind of object `X_train` is. How do you make sure it is in the correct shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.41591714e+01, 1.92330047e+01, 9.21438967e+01, 6.58415023e+02,\n",
       "        9.63659859e-02, 1.03669601e-01, 8.86501308e-02, 4.91440610e-02,\n",
       "        1.80473239e-01, 6.26169953e-02, 4.04795070e-01, 1.21222723e+00,\n",
       "        2.84097934e+00, 4.06956737e+01, 6.98667371e-03, 2.50779930e-02,\n",
       "        3.16993207e-02, 1.17015352e-02, 2.04367559e-02, 3.71274953e-03,\n",
       "        1.63168169e+01, 2.56379812e+01, 1.07459131e+02, 8.87647887e+02,\n",
       "        1.32503404e-01, 2.52836338e-01, 2.69481120e-01, 1.15279345e-01,\n",
       "        2.89649296e-01, 8.35402582e-02]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.mean().values.reshape(-1, X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(X_train.mean().values.reshape(-1, X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dce8523408e514c96bdcac3e4867526c",
     "grade": false,
     "grade_id": "cell-bbc431b30a17745f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_six():\n",
    "    pred = None\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    knn = answer_five()\n",
    "    pred = knn.predict(X_train.mean().values.reshape(-1,X_train.shape[-1]))\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use this cell to explore your solution\n",
    "# # remember to comment the function call before submitting the notebook\n",
    "\n",
    "# answer_six()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "494638ad6ea8a1ed997da2a1028c34d1",
     "grade": true,
     "grade_id": "cell-c93e4911f581b5cb",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_six()\n",
    "\n",
    "assert isinstance(stu_ans, np.ndarray), \"Q6: Your function should return a np.ndarray. \"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "acebbf177184da50e3d30ea12c5b5f97",
     "grade": false,
     "grade_id": "cell-cba29490ecc74222",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 7. kNN Prediction on the Test Set (5 pts)\n",
    "\n",
    "Now, use your kNN classifier to predict class labels for the test set `X_test`. Your function should return a binary `np.ndarray` of the shape `(143,)` whose values are either `0.0` or `1.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e107bb6824f6be3f617fa6a1d4dd20a",
     "grade": false,
     "grade_id": "cell-556e3b89a523853a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_seven():\n",
    "    preds = None\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    knn = answer_five()\n",
    "    preds = knn.predict(X_test)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # use this cell to explore your solution\n",
    "# # remember to comment the function call before submitting the notebook\n",
    "\n",
    "answer_seven()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1eb28af45e0c38e4506e3b11fa04622f",
     "grade": true,
     "grade_id": "cell-1fc7ffa2d7e05814",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_seven()\n",
    "assert isinstance(stu_ans, np.ndarray), \"Q7: Your function should return a np.ndarray. \"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "01c3548a6770290943242e4572fa04fa",
     "grade": false,
     "grade_id": "cell-9b690a899cf1faea",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 8. Evaluation on the Test Set (5 pts) \n",
    "\n",
    "Once you have the predictions on the test set, you may compare them with the ground-truth labels to gauge how well your model performs when given unseen data. \n",
    "\n",
    "Complete the function below to compute the score (mean accuracy) of your kNN classifier using the test set `X_test` and the test labels `y_test`. The function should return a `float` between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.951048951048951"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1bf802ee4c89a4d268d89bc3a4c743ec",
     "grade": false,
     "grade_id": "cell-dc56668e96e99a63",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_eight():\n",
    "    score = None\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    knn = answer_five()\n",
    "    score = knn.score(X_test, y_test)\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9300699300699301"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # use this cell to explore your solution\n",
    "# # remember to comment the function call before submitting the notebook\n",
    "\n",
    "answer_eight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43e6c71469a655accc05570c3f17ac5a",
     "grade": true,
     "grade_id": "cell-edfa0ff11db4a6d9",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_eight()\n",
    "\n",
    "assert isinstance(stu_ans, float), \"Q8: Your function should return a float. \"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d1a0f52203e63c19ba5d6d00fbc04161",
     "grade": false,
     "grade_id": "cell-2f4bb718715b7db8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Optional: Accuracy Plot\n",
    "\n",
    "Note: The following plots will help you to evaluate the model with showing the prediction accuracy in training and testing set.  You can pass in any trained classifier as the argument.  \n",
    "\n",
    "Try using the plotting function below to visualize the different predicition scores between training and test sets, as well as malignant and benign cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58301e6ddde061761b222041b96694cb",
     "grade": false,
     "grade_id": "cell-3a29268b05bec923",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def accuracy_plot(knn):\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "\n",
    "    # Find the training and testing accuracies by target value (i.e. malignant, benign)\n",
    "    mal_train_X = X_train[y_train == 0]\n",
    "    mal_train_y = y_train[y_train == 0]\n",
    "    ben_train_X = X_train[y_train == 1]\n",
    "    ben_train_y = y_train[y_train == 1]\n",
    "\n",
    "    mal_test_X = X_test[y_test == 0]\n",
    "    mal_test_y = y_test[y_test == 0]\n",
    "    ben_test_X = X_test[y_test == 1]\n",
    "    ben_test_y = y_test[y_test == 1]\n",
    "\n",
    "    scores = [\n",
    "        knn.score(mal_train_X, mal_train_y),\n",
    "        knn.score(ben_train_X, ben_train_y),\n",
    "        knn.score(mal_test_X, mal_test_y),\n",
    "        knn.score(ben_test_X, ben_test_y),\n",
    "    ]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Plot the scores as a bar chart\n",
    "    bars = plt.bar(\n",
    "        np.arange(4), scores, color=[\"#4c72b0\", \"#4c72b0\", \"#55a868\", \"#55a868\"]\n",
    "    )\n",
    "\n",
    "    # directly label the score onto the bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.gca().text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            height * 0.90,\n",
    "            \"{0:.{1}f}\".format(height, 2),\n",
    "            ha=\"center\",\n",
    "            color=\"w\",\n",
    "            fontsize=11,\n",
    "        )\n",
    "\n",
    "    # remove all the ticks (both axes), and tick labels on the Y axis\n",
    "    plt.tick_params(\n",
    "        top=\"off\",\n",
    "        bottom=\"off\",\n",
    "        left=\"off\",\n",
    "        right=\"off\",\n",
    "        labelleft=\"off\",\n",
    "        labelbottom=\"on\",\n",
    "    )\n",
    "\n",
    "    # remove the frame of the chart\n",
    "    for spine in plt.gca().spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    plt.xticks(\n",
    "        [0, 1, 2, 3],\n",
    "        [\"Malignant\\nTraining\", \"Benign\\nTraining\", \"Malignant\\nTest\", \"Benign\\nTest\"],\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    plt.title(\"Training and Test Accuracies for Malignant and Benign Cells\", alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Uncomment the call below line to view the visualization\n",
    "# # Remember to comment the call before submitting the notebook to the autograder\n",
    "\n",
    "accuracy_plot(answer_five())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "807700a4417faf916e02ea785683f07f",
     "grade": false,
     "grade_id": "cell-7d573c035102d74b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 9. Hyper-parameter Tuning (5 pts)\n",
    "\n",
    "It's common to experiment with different configurations of a model, also known as \"hyper-parameters\" which are typically specified in advance of starting the step of estimating the learnable \"parameters\" of a specific model configuration in order to achieve better performance. The main crucial hyper-parameter of a k-NN model is the number $k$, the number of neighbors to examine. \n",
    "\n",
    "Change $k$ to 15 and fit the model with training data. Complete the function below to return the trained model, which is a `sklearn.neighbors.KNeighborsClassifier` object. Compare this with the results above for $k$ = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ba7f7115c6acb307369b7b7232a6be1",
     "grade": false,
     "grade_id": "cell-3bc80326a3e99e05",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "def answer_nine():\n",
    "    knn = None\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    knn = KNeighborsClassifier(n_neighbors = 15)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=15)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=15)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=15)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # use this cell to explore your solution\n",
    "# # remember to comment the function call before submitting the notebook\n",
    "\n",
    "answer_nine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d2eefdfacf81d7798c2bce507b3fc32",
     "grade": true,
     "grade_id": "cell-e724a46e381ed1b7",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_nine()\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans, KNeighborsClassifier\n",
    "), \"Q9: Please build the required kNN classifier.\"\n",
    "\n",
    "assert (\n",
    "    len(stu_ans.classes_) == 2\n",
    "), \"Q9: Your kNN classifier was trained with an incorrect # classes. \"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment the call below line to view the visualization\n",
    "# # Remember to comment the call before submitting the notebook to the autograder\n",
    "\n",
    "# accuracy_plot(answer_nine())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0905268f819993696d61ad9f9e1738d2",
     "grade": false,
     "grade_id": "cell-67fb7570879a6ed9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 10. Weighted k-NN (5 pts)\n",
    "\n",
    "Keeping $k = 15$, now change the k-NN method to use a *weighted* distance measure: this means closer neighbors of a query point will have more influence on the prediction than neighbors which are a greater distance away. (Normally, the default k-NN classifier uses a uniform weighting, i.e. it ignores how far a neighbor is and just sees that it exists.)\n",
    "\n",
    "Your function below should return a trained kNN classifier of the type `sklearn.neighbors.KNeighborsClassifier`. (You may find it helpful to plot and compare the results with the unweighted distance measure, using the provided plotting function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c467397f2f7c748352c9701ffd195b75",
     "grade": false,
     "grade_id": "cell-4243c4d7cfa2960e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_ten():\n",
    "    knn = None\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    knn = KNeighborsClassifier(n_neighbors = 15,weights='distance')\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use this cell to explore your solution\n",
    "# # remember to comment the function call before submitting the notebook\n",
    "\n",
    "# answer_ten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "508fc0b6ac79738240ba6b59714208da",
     "grade": true,
     "grade_id": "cell-558b71c1a69189f5",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_ten()\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans, KNeighborsClassifier\n",
    "), \"Q9: Please build the required kNN classifier.\"\n",
    "\n",
    "assert (\n",
    "    len(stu_ans.classes_) == 2\n",
    "), \"Q9: Your kNN classifier was trained with an incorrect # classes. \"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment the call below line to view the visualization\n",
    "# # Remember to comment the call before submitting the notebook to the autograder\n",
    "\n",
    "# accuracy_plot(answer_ten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40c306fde694591056a5b00cb143a058",
     "grade": false,
     "grade_id": "cell-991ef995f3f147aa",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 11: Model parameter tuning (15 points)\n",
    "\n",
    "It is important to improve algorithm design through automatically changing the parameter based on data-driven evidence, because it is more effective than just 'trying out' different parameters by hand.\n",
    "\n",
    "Perform a simple parameter sweep for all **odd** values of $k$ from 1 to 19 inclusive, and return the optimal value of $k$ that leads to the highest overall *test set accuracy* on this train/test split.  Accuracy is computed using the **score** method. Your code should return an integer between 1 and 19. In case of a tie, return the smallest best $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "41bb7e821ef7f6a2c82c9a0eac9cce76",
     "grade": false,
     "grade_id": "cell-feeb5e4810d6c9e6",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_eleven():\n",
    "    k_best = None\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    scores = []\n",
    "    k = range(1,19+1,2)\n",
    "    for i in k :\n",
    "        knn = KNeighborsClassifier(n_neighbors = i)\n",
    "        knn.fit(X_train, y_train)\n",
    "        scores.append(knn.score(X_test, y_test))\n",
    "    #k_best = int(np.argsort([-i for i in scores])[0])\n",
    "    k_best = k[int(np.argsort(scores)[-1])]\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    return k_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use this cell to explore your solution\n",
    "# # remember to comment the function call before submitting the notebook\n",
    "\n",
    "# answer_eleven()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23fa51cf747fbd00ac1d5bc2253c707d",
     "grade": true,
     "grade_id": "cell-e17d6199583d1080",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_eleven()\n",
    "\n",
    "assert isinstance(stu_ans, int), \"Q11: Your function should return an integer. \"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12: Overfitting  (15 points)\n",
    "\n",
    "A key sign of overfitting is obtaining a training set accuracy that is extremely high (or even perfect), but a test set accuracy that is considerably lower. It is tempting to use a classifier that does so well on the training data it was given, but reality sets in when we try to use this overfit classifier on new test data and we discover it does not in fact generalize well.\n",
    "\n",
    "Using the same set of possible k-NN classifiers and values of $k$ as the previous question (Q11), look for a scenario where overfitting is likely to be happening, by finding the optimal value for $k$ if your goal was to pick the classifier that did best only on the **training set**.  Compute what the resulting test set accuracy would have been, if you had picked that training-set-based value for $k$.\n",
    "\n",
    "Your function should return an (`int`, `float`, `float`) tuple, as follows:\n",
    "\n",
    "`tuple[0]`: the optimal value of $k$ that maximizes *training set* accuracy\n",
    "\n",
    "`tuple[1]`: the corresponding *training set* accuracy for that optimal $k$\n",
    "\n",
    "`tuple[2]`: the corresponding *test set* accuracy that you would have received *if* you had used that optimal $k$.\n",
    "\n",
    "(It is instructive to compare this test set accuracy with the best one you were able to achieve in question 11.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8582d7c83b37ebb6013b8a9e1899de7",
     "grade": false,
     "grade_id": "cell-fa4b5a5c9ec7dd40",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_twelve():\n",
    "    k_best = None\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    k = range(1,19+1,2)\n",
    "    for i in k :\n",
    "        knn = KNeighborsClassifier(n_neighbors = i)\n",
    "        knn.fit(X_train, y_train)\n",
    "        train_scores.append(knn.score(X_train, y_train))\n",
    "        test_scores.append(knn.score(X_test, y_test))\n",
    "    #k_best = int(np.argsort([-i for i in scores])[0])\n",
    "    k_best = k[int(np.argsort(train_scores)[-1])], train_scores[int(np.argsort(train_scores)[-1])], test_scores[int(np.argsort(train_scores)[-1])]\n",
    "\n",
    "    return k_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use this cell to explore your solution\n",
    "# # remember to comment the function call before submitting the notebook\n",
    "\n",
    "# answer_twelve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a85f37e303c830c4605c580dfd7c9e5",
     "grade": true,
     "grade_id": "cell-9d8ba54a5e282cd7",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_twelve()\n",
    "\n",
    "assert isinstance(stu_ans, tuple), \"Q12: Your function should return a tuple. \"\n",
    "assert len(stu_ans) == 3, \"Q12: The length of your returned tuple should be 3. \"\n",
    "assert isinstance(\n",
    "    stu_ans[0], int\n",
    "), \"Q12: Your tuple format should be (*int*, float, float). \"\n",
    "assert isinstance(\n",
    "    stu_ans[1], float\n",
    "), \"Q12: Your tuple format should be (int, *float*, float). \"\n",
    "assert isinstance(\n",
    "    stu_ans[1], float\n",
    "), \"Q12: Your tuple format should be (int, float, *float*). \"\n",
    "\n",
    "\n",
    "del stu_ans"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mads_supervised_learning_v2_assignment1_part2"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
